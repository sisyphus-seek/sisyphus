# LLM API Configuration (OpenAI-compatible)
# 支持 OpenAI, Azure OpenAI, 本地部署的兼容服务等
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo

# 兼容旧的环境变量名（可选，会优先使用 LLM_API_KEY）
OPENAI_API_KEY=

# ASR Model Configuration
GLM_ASR_MODEL=THUDM/glm-4-voice-9b

# TTS Model Configuration
QWEN_TTS_MODEL=Qwen/Qwen2.5-1.5B-Instruct

# Python 推理服务配置
ASR_HOST=127.0.0.1
ASR_PORT=8765
TTS_HOST=127.0.0.1
TTS_PORT=8766

# Audio pipeline configuration
# Must match ASR/TTS target sample rate
AUDIO_SAMPLE_RATE=16000
# Frame size in milliseconds for WS audio chunks
AUDIO_FRAME_MS=20

# LLM -> TTS chunking (lower values = lower latency, higher overhead)
LLM_TTS_MIN_CHUNK_TOKENS=20
LLM_TTS_MAX_CHUNK_MS=300

# CUDA 配置
CUDA_VISIBLE_DEVICES=0
