# âœ… .env ç¯å¢ƒå˜é‡é…ç½®å®Œæˆæ€»ç»“

## ğŸ¯ å®Œæˆçš„å·¥ä½œ

### 1. åˆ›å»º .env é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: [.env](.env) å’Œ [.env.example](.env.example)

```env
# LLM API é…ç½®ï¼ˆOpenAI-compatibleï¼‰
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo

# å…¼å®¹æ—§å˜é‡
OPENAI_API_KEY=

# ASR/TTS æ¨¡å‹
GLM_ASR_MODEL=THUDM/glm-4-voice-9b
QWEN_TTS_MODEL=Qwen/Qwen2.5-1.5B-Instruct

# æ¨ç†æœåŠ¡é…ç½®
ASR_HOST=127.0.0.1
ASR_PORT=8765
TTS_HOST=127.0.0.1
TTS_PORT=8766

# CUDA é…ç½®
CUDA_VISIBLE_DEVICES=0
```

### 2. Rust ç«¯é›†æˆ

**ä¿®æ”¹çš„æ–‡ä»¶**:
- [src-tauri/Cargo.toml](src-tauri/Cargo.toml) - æ·»åŠ  `dotenvy = "0.15"`
- [src-tauri/src/lib.rs](src-tauri/src/lib.rs) - åŠ è½½ .env æ–‡ä»¶
- [src-tauri/src/llm/client.rs](src-tauri/src/llm/client.rs) - æ”¯æŒå¯é…ç½® base_url å’Œ model

**å…³é”®å®ç°**:

```rust
// lib.rs - å¯åŠ¨æ—¶åŠ è½½ .env
pub fn run() {
    if let Err(e) = dotenvy::dotenv() {
        eprintln!("Warning: Failed to load .env file: {}", e);
    }
    // ...
}

// llm/client.rs - è¯»å–é…ç½®
impl LlmClient {
    pub fn new() -> Result<Self> {
        let api_key = env::var("LLM_API_KEY")
            .or_else(|_| env::var("OPENAI_API_KEY"))?;

        let base_url = env::var("LLM_BASE_URL")
            .unwrap_or_else(|_| "https://api.openai.com/v1".to_string());

        let model = env::var("LLM_MODEL")
            .unwrap_or_else(|_| "gpt-3.5-turbo".to_string());

        let config = OpenAIConfig::default()
            .with_api_key(api_key)
            .with_api_base(base_url);

        Ok(Self { client, model })
    }
}
```

### 3. Python ç«¯å‡†å¤‡

**ä¿®æ”¹çš„æ–‡ä»¶**:
- [inference/requirements-asr.txt](inference/requirements-asr.txt) - æ·»åŠ ä¾èµ–
- [inference/requirements-tts.txt](inference/requirements-tts.txt) - æ·»åŠ ä¾èµ–

**æ·»åŠ çš„ä¾èµ–**:
```txt
python-dotenv>=1.0.0
openai>=1.0.0
```

**ç¤ºä¾‹æ–‡ä»¶**: [inference/llm_client_example.py](inference/llm_client_example.py)

```python
from dotenv import load_dotenv
from openai import OpenAI
import os

load_dotenv()

API_KEY = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
BASE_URL = os.getenv("LLM_BASE_URL", "https://api.openai.com/v1")
MODEL = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
```

### 4. æ–‡æ¡£

åˆ›å»ºäº† [docs/ENV_CONFIGURATION.md](docs/ENV_CONFIGURATION.md)ï¼ŒåŒ…å«ï¼š
- é…ç½®é¡¹è¯´æ˜
- ä½¿ç”¨ç¤ºä¾‹ï¼ˆOpenAIã€Azureã€æœ¬åœ°éƒ¨ç½²ã€å›½å†… APIï¼‰
- æŠ€æœ¯å®ç°ç»†èŠ‚
- ä¾èµ–å®‰è£…è¯´æ˜
- å¸¸è§é—®é¢˜

---

## ğŸ‰ å…³é”®ç‰¹æ€§

### âœ… OpenAI-Compatible API æ”¯æŒ

æ”¯æŒä»»ä½•å…¼å®¹ OpenAI API çš„æœåŠ¡ï¼š
- OpenAI å®˜æ–¹
- Azure OpenAI
- æœ¬åœ°éƒ¨ç½²ï¼ˆOllamaã€vLLMã€LM Studioï¼‰
- å›½å†… APIï¼ˆæ™ºè°± GLMã€æœˆä¹‹æš—é¢ Kimiã€ç™¾å·ã€é˜¿é‡Œé€šä¹‰åƒé—®ç­‰ï¼‰

### âœ… ç»Ÿä¸€é…ç½®ç®¡ç†

ä¸‰ä¸ªå…³é”®é…ç½®é¡¹ï¼š
1. `LLM_API_KEY` - API å¯†é’¥
2. `LLM_BASE_URL` - API åŸºç¡€ URL
3. `LLM_MODEL` - æ¨¡å‹åç§°

### âœ… å‘åå…¼å®¹

- æ”¯æŒ `OPENAI_API_KEY` ç¯å¢ƒå˜é‡ï¼ˆä¼˜å…ˆä½¿ç”¨ `LLM_API_KEY`ï¼‰
- æ‰€æœ‰é…ç½®éƒ½æœ‰é»˜è®¤å€¼ï¼ˆé»˜è®¤æŒ‡å‘ OpenAI APIï¼‰

### âœ… æ— éœ€ tiktoken

- Python ä½¿ç”¨ `openai>=1.0.0`ï¼ˆæ–°ç‰ˆ APIï¼‰
- ä¸ä¾èµ– tiktoken åŒ…
- ç®€åŒ–éƒ¨ç½²æµç¨‹

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. é…ç½® .env æ–‡ä»¶

å¤åˆ¶ `.env.example` åˆ° `.env` å¹¶å¡«å…¥ä½ çš„é…ç½®ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env`ï¼š

```env
LLM_API_KEY=sk-your-actual-key
LLM_BASE_URL=https://api.openai.com/v1  # æˆ–å…¶ä»–å…¼å®¹æœåŠ¡
LLM_MODEL=gpt-3.5-turbo  # æˆ–å…¶ä»–æ¨¡å‹
```

### 2. å®‰è£… Python ä¾èµ–

```bash
# ASR ç¯å¢ƒ
cd inference
venv\Scripts\activate
pip install -r requirements-asr.txt

# TTS ç¯å¢ƒ
venv-tts\Scripts\activate
pip install -r requirements-tts.txt
```

### 3. æµ‹è¯•é…ç½®

**æµ‹è¯• Python**:
```bash
cd inference
venv\Scripts\activate
python llm_client_example.py
```

**æµ‹è¯• Rust**:
```bash
cd src-tauri
cargo build  # ç¼–è¯‘æˆåŠŸå³è¡¨ç¤ºé…ç½®æ­£ç¡®
```

### 4. è¿è¡Œåº”ç”¨

```bash
# å¯åŠ¨æ¨ç†æœåŠ¡
cd inference
start_both.bat  # æˆ–åˆ†åˆ«å¯åŠ¨ ASR å’Œ TTS

# å¯åŠ¨ Tauri åº”ç”¨
cd ..
npm run tauri dev
```

---

## ğŸ“‹ é…ç½®ç¤ºä¾‹

### OpenAI å®˜æ–¹

```env
LLM_API_KEY=sk-proj-xxxx
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo
```

### æ™ºè°± GLM-4

```env
LLM_API_KEY=your-zhipu-key.xxx
LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
LLM_MODEL=glm-4
```

### æœ¬åœ° Ollama

```env
LLM_API_KEY=ollama  # ä»»æ„å€¼
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=llama2
```

### æœˆä¹‹æš—é¢ Kimi

```env
LLM_API_KEY=sk-xxx
LLM_BASE_URL=https://api.moonshot.cn/v1
LLM_MODEL=moonshot-v1-8k
```

---

## âœ¨ ä¼˜åŠ¿

1. **çµæ´»æ€§**: è½»æ¾åˆ‡æ¢ä¸åŒçš„ LLM æä¾›å•†
2. **å®‰å…¨æ€§**: API Key ä¸ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
3. **ç»Ÿä¸€ç®¡ç†**: ä¸€ä¸ª .env æ–‡ä»¶ç®¡ç†æ‰€æœ‰é…ç½®
4. **å‘åå…¼å®¹**: æ”¯æŒæ—§çš„ç¯å¢ƒå˜é‡å
5. **ç®€å•éƒ¨ç½²**: ä¸ä¾èµ– tiktoken ç­‰å¤æ‚åŒ…

---

## ğŸ” å®‰å…¨æé†’

- âš ï¸ **æ°¸è¿œä¸è¦æäº¤ .env æ–‡ä»¶åˆ° Git**
- `.env` å·²æ·»åŠ åˆ° `.gitignore`
- ä½¿ç”¨ `.env.example` ä½œä¸ºé…ç½®æ¨¡æ¿
- ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡

---

## ğŸ“Š ç¼–è¯‘çŠ¶æ€

âœ… Rust ç¼–è¯‘æˆåŠŸï¼ˆ`cargo build` é€šè¿‡ï¼‰
âœ… æ·»åŠ äº† `dotenvy = "0.15"` ä¾èµ–
âœ… æ”¯æŒ `async-openai` 0.14 çš„è‡ªå®šä¹‰ base_url é…ç½®

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. åœ¨ `.env` ä¸­å¡«å…¥å®é™…çš„ API Key
2. æ ¹æ®ä½¿ç”¨çš„æœåŠ¡è°ƒæ•´ BASE_URL å’Œ MODEL
3. å®‰è£… Python ä¾èµ–ï¼ˆ`pip install -r requirements-*.txt`ï¼‰
4. æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹

---

**é…ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨ä»»ä½• OpenAI-compatible API äº†ï¼** ğŸš€
